{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"_models/","title":"_models","text":""},{"location":"_models/#_models","title":"<code>_models</code>","text":""},{"location":"_models/#_models.BaseModel","title":"<code>BaseModel</code>","text":"<p>             Bases: <code>BaseModel</code></p> Source code in <code>src/anthropic/_models.py</code> <pre><code>class BaseModel(pydantic.BaseModel):\n    if PYDANTIC_V2:\n        model_config: ClassVar[ConfigDict] = ConfigDict(\n            extra=\"allow\", defer_build=coerce_boolean(os.environ.get(\"DEFER_PYDANTIC_BUILD\", \"true\"))\n        )\n    else:\n\n        @property\n        @override\n        def model_fields_set(self) -&gt; set[str]:\n            # a forwards-compat shim for pydantic v2\n            return self.__fields_set__  # type: ignore\n\n        class Config(pydantic.BaseConfig):  # pyright: ignore[reportDeprecated]\n            extra: Any = pydantic.Extra.allow  # type: ignore\n\n    def to_dict(\n        self,\n        *,\n        mode: Literal[\"json\", \"python\"] = \"python\",\n        use_api_names: bool = True,\n        exclude_unset: bool = True,\n        exclude_defaults: bool = False,\n        exclude_none: bool = False,\n        warnings: bool = True,\n    ) -&gt; dict[str, object]:\n        \"\"\"Recursively generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n\n        By default, fields that were not set by the API will not be included,\n        and keys will match the API response, *not* the property names from the model.\n\n        For example, if the API responds with `\"fooBar\": true` but we've defined a `foo_bar: bool` property,\n        the output will use the `\"fooBar\"` key (unless `use_api_names=False` is passed).\n\n        Args:\n            mode:\n                If mode is 'json', the dictionary will only contain JSON serializable types. e.g. `datetime` will be turned into a string, `\"2024-3-22T18:11:19.117000Z\"`.\n                If mode is 'python', the dictionary may contain any Python objects. e.g. `datetime(2024, 3, 22)`\n\n            use_api_names: Whether to use the key that the API responded with or the property name. Defaults to `True`.\n            exclude_unset: Whether to exclude fields that have not been explicitly set.\n            exclude_defaults: Whether to exclude fields that are set to their default value from the output.\n            exclude_none: Whether to exclude fields that have a value of `None` from the output.\n            warnings: Whether to log warnings when invalid fields are encountered. This is only supported in Pydantic v2.\n        \"\"\"\n        return self.model_dump(\n            mode=mode,\n            by_alias=use_api_names,\n            exclude_unset=exclude_unset,\n            exclude_defaults=exclude_defaults,\n            exclude_none=exclude_none,\n            warnings=warnings,\n        )\n\n    def to_json(\n        self,\n        *,\n        indent: int | None = 2,\n        use_api_names: bool = True,\n        exclude_unset: bool = True,\n        exclude_defaults: bool = False,\n        exclude_none: bool = False,\n        warnings: bool = True,\n    ) -&gt; str:\n        \"\"\"Generates a JSON string representing this model as it would be received from or sent to the API (but with indentation).\n\n        By default, fields that were not set by the API will not be included,\n        and keys will match the API response, *not* the property names from the model.\n\n        For example, if the API responds with `\"fooBar\": true` but we've defined a `foo_bar: bool` property,\n        the output will use the `\"fooBar\"` key (unless `use_api_names=False` is passed).\n\n        Args:\n            indent: Indentation to use in the JSON output. If `None` is passed, the output will be compact. Defaults to `2`\n            use_api_names: Whether to use the key that the API responded with or the property name. Defaults to `True`.\n            exclude_unset: Whether to exclude fields that have not been explicitly set.\n            exclude_defaults: Whether to exclude fields that have the default value.\n            exclude_none: Whether to exclude fields that have a value of `None`.\n            warnings: Whether to show any warnings that occurred during serialization. This is only supported in Pydantic v2.\n        \"\"\"\n        return self.model_dump_json(\n            indent=indent,\n            by_alias=use_api_names,\n            exclude_unset=exclude_unset,\n            exclude_defaults=exclude_defaults,\n            exclude_none=exclude_none,\n            warnings=warnings,\n        )\n\n    @override\n    def __str__(self) -&gt; str:\n        # mypy complains about an invalid self arg\n        return f'{self.__repr_name__()}({self.__repr_str__(\", \")})'  # type: ignore[misc]\n\n    # Override the 'construct' method in a way that supports recursive parsing without validation.\n    # Based on https://github.com/samuelcolvin/pydantic/issues/1168#issuecomment-817742836.\n    @classmethod\n    @override\n    def construct(\n        cls: Type[ModelT],\n        _fields_set: set[str] | None = None,\n        **values: object,\n    ) -&gt; ModelT:\n        m = cls.__new__(cls)\n        fields_values: dict[str, object] = {}\n\n        config = get_model_config(cls)\n        populate_by_name = (\n            config.allow_population_by_field_name\n            if isinstance(config, _ConfigProtocol)\n            else config.get(\"populate_by_name\")\n        )\n\n        if _fields_set is None:\n            _fields_set = set()\n\n        model_fields = get_model_fields(cls)\n        for name, field in model_fields.items():\n            key = field.alias\n            if key is None or (key not in values and populate_by_name):\n                key = name\n\n            if key in values:\n                fields_values[name] = _construct_field(value=values[key], field=field, key=key)\n                _fields_set.add(name)\n            else:\n                fields_values[name] = field_get_default(field)\n\n        _extra = {}\n        for key, value in values.items():\n            if key not in model_fields:\n                if PYDANTIC_V2:\n                    _extra[key] = value\n                else:\n                    _fields_set.add(key)\n                    fields_values[key] = value\n\n        object.__setattr__(m, \"__dict__\", fields_values)\n\n        if PYDANTIC_V2:\n            # these properties are copied from Pydantic's `model_construct()` method\n            object.__setattr__(m, \"__pydantic_private__\", None)\n            object.__setattr__(m, \"__pydantic_extra__\", _extra)\n            object.__setattr__(m, \"__pydantic_fields_set__\", _fields_set)\n        else:\n            # init_private_attributes() does not exist in v2\n            m._init_private_attributes()  # type: ignore\n\n            # copied from Pydantic v1's `construct()` method\n            object.__setattr__(m, \"__fields_set__\", _fields_set)\n\n        return m\n\n    if not TYPE_CHECKING:\n        # type checkers incorrectly complain about this assignment\n        # because the type signatures are technically different\n        # although not in practice\n        model_construct = construct\n\n    if not PYDANTIC_V2:\n        # we define aliases for some of the new pydantic v2 methods so\n        # that we can just document these methods without having to specify\n        # a specific pydantic version as some users may not know which\n        # pydantic version they are currently using\n\n        @override\n        def model_dump(\n            self,\n            *,\n            mode: Literal[\"json\", \"python\"] | str = \"python\",\n            include: IncEx = None,\n            exclude: IncEx = None,\n            by_alias: bool = False,\n            exclude_unset: bool = False,\n            exclude_defaults: bool = False,\n            exclude_none: bool = False,\n            round_trip: bool = False,\n            warnings: bool = True,\n        ) -&gt; dict[str, Any]:\n            \"\"\"Usage docs: https://docs.pydantic.dev/2.4/concepts/serialization/#modelmodel_dump\n\n            Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n\n            Args:\n                mode: The mode in which `to_python` should run.\n                    If mode is 'json', the dictionary will only contain JSON serializable types.\n                    If mode is 'python', the dictionary may contain any Python objects.\n                include: A list of fields to include in the output.\n                exclude: A list of fields to exclude from the output.\n                by_alias: Whether to use the field's alias in the dictionary key if defined.\n                exclude_unset: Whether to exclude fields that are unset or None from the output.\n                exclude_defaults: Whether to exclude fields that are set to their default value from the output.\n                exclude_none: Whether to exclude fields that have a value of `None` from the output.\n                round_trip: Whether to enable serialization and deserialization round-trip support.\n                warnings: Whether to log warnings when invalid fields are encountered.\n\n            Returns:\n                A dictionary representation of the model.\n            \"\"\"\n            if mode != \"python\":\n                raise ValueError(\"mode is only supported in Pydantic v2\")\n            if round_trip != False:\n                raise ValueError(\"round_trip is only supported in Pydantic v2\")\n            if warnings != True:\n                raise ValueError(\"warnings is only supported in Pydantic v2\")\n            return super().dict(  # pyright: ignore[reportDeprecated]\n                include=include,\n                exclude=exclude,\n                by_alias=by_alias,\n                exclude_unset=exclude_unset,\n                exclude_defaults=exclude_defaults,\n                exclude_none=exclude_none,\n            )\n\n        @override\n        def model_dump_json(\n            self,\n            *,\n            indent: int | None = None,\n            include: IncEx = None,\n            exclude: IncEx = None,\n            by_alias: bool = False,\n            exclude_unset: bool = False,\n            exclude_defaults: bool = False,\n            exclude_none: bool = False,\n            round_trip: bool = False,\n            warnings: bool = True,\n        ) -&gt; str:\n            \"\"\"Usage docs: https://docs.pydantic.dev/2.4/concepts/serialization/#modelmodel_dump_json\n\n            Generates a JSON representation of the model using Pydantic's `to_json` method.\n\n            Args:\n                indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n                include: Field(s) to include in the JSON output. Can take either a string or set of strings.\n                exclude: Field(s) to exclude from the JSON output. Can take either a string or set of strings.\n                by_alias: Whether to serialize using field aliases.\n                exclude_unset: Whether to exclude fields that have not been explicitly set.\n                exclude_defaults: Whether to exclude fields that have the default value.\n                exclude_none: Whether to exclude fields that have a value of `None`.\n                round_trip: Whether to use serialization/deserialization between JSON and class instance.\n                warnings: Whether to show any warnings that occurred during serialization.\n\n            Returns:\n                A JSON string representation of the model.\n            \"\"\"\n            if round_trip != False:\n                raise ValueError(\"round_trip is only supported in Pydantic v2\")\n            if warnings != True:\n                raise ValueError(\"warnings is only supported in Pydantic v2\")\n            return super().json(  # type: ignore[reportDeprecated]\n                indent=indent,\n                include=include,\n                exclude=exclude,\n                by_alias=by_alias,\n                exclude_unset=exclude_unset,\n                exclude_defaults=exclude_defaults,\n                exclude_none=exclude_none,\n            )\n</code></pre>"},{"location":"_models/#_models.BaseModel.model_dump","title":"<code>model_dump(*, mode='python', include=None, exclude=None, by_alias=False, exclude_unset=False, exclude_defaults=False, exclude_none=False, round_trip=False, warnings=True)</code>","text":"<p>Usage docs: https://docs.pydantic.dev/2.4/concepts/serialization/#modelmodel_dump</p> <p>Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>Literal['json', 'python'] | str</code> <p>The mode in which <code>to_python</code> should run. If mode is 'json', the dictionary will only contain JSON serializable types. If mode is 'python', the dictionary may contain any Python objects.</p> <code>'python'</code> <code>include</code> <code>IncEx</code> <p>A list of fields to include in the output.</p> <code>None</code> <code>exclude</code> <code>IncEx</code> <p>A list of fields to exclude from the output.</p> <code>None</code> <code>by_alias</code> <code>bool</code> <p>Whether to use the field's alias in the dictionary key if defined.</p> <code>False</code> <code>exclude_unset</code> <code>bool</code> <p>Whether to exclude fields that are unset or None from the output.</p> <code>False</code> <code>exclude_defaults</code> <code>bool</code> <p>Whether to exclude fields that are set to their default value from the output.</p> <code>False</code> <code>exclude_none</code> <code>bool</code> <p>Whether to exclude fields that have a value of <code>None</code> from the output.</p> <code>False</code> <code>round_trip</code> <code>bool</code> <p>Whether to enable serialization and deserialization round-trip support.</p> <code>False</code> <code>warnings</code> <code>bool</code> <p>Whether to log warnings when invalid fields are encountered.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>A dictionary representation of the model.</p> Source code in <code>src/anthropic/_models.py</code> <pre><code>@override\ndef model_dump(\n    self,\n    *,\n    mode: Literal[\"json\", \"python\"] | str = \"python\",\n    include: IncEx = None,\n    exclude: IncEx = None,\n    by_alias: bool = False,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: bool = True,\n) -&gt; dict[str, Any]:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.4/concepts/serialization/#modelmodel_dump\n\n    Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n\n    Args:\n        mode: The mode in which `to_python` should run.\n            If mode is 'json', the dictionary will only contain JSON serializable types.\n            If mode is 'python', the dictionary may contain any Python objects.\n        include: A list of fields to include in the output.\n        exclude: A list of fields to exclude from the output.\n        by_alias: Whether to use the field's alias in the dictionary key if defined.\n        exclude_unset: Whether to exclude fields that are unset or None from the output.\n        exclude_defaults: Whether to exclude fields that are set to their default value from the output.\n        exclude_none: Whether to exclude fields that have a value of `None` from the output.\n        round_trip: Whether to enable serialization and deserialization round-trip support.\n        warnings: Whether to log warnings when invalid fields are encountered.\n\n    Returns:\n        A dictionary representation of the model.\n    \"\"\"\n    if mode != \"python\":\n        raise ValueError(\"mode is only supported in Pydantic v2\")\n    if round_trip != False:\n        raise ValueError(\"round_trip is only supported in Pydantic v2\")\n    if warnings != True:\n        raise ValueError(\"warnings is only supported in Pydantic v2\")\n    return super().dict(  # pyright: ignore[reportDeprecated]\n        include=include,\n        exclude=exclude,\n        by_alias=by_alias,\n        exclude_unset=exclude_unset,\n        exclude_defaults=exclude_defaults,\n        exclude_none=exclude_none,\n    )\n</code></pre>"},{"location":"_models/#_models.BaseModel.model_dump_json","title":"<code>model_dump_json(*, indent=None, include=None, exclude=None, by_alias=False, exclude_unset=False, exclude_defaults=False, exclude_none=False, round_trip=False, warnings=True)</code>","text":"<p>Usage docs: https://docs.pydantic.dev/2.4/concepts/serialization/#modelmodel_dump_json</p> <p>Generates a JSON representation of the model using Pydantic's <code>to_json</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>indent</code> <code>int | None</code> <p>Indentation to use in the JSON output. If None is passed, the output will be compact.</p> <code>None</code> <code>include</code> <code>IncEx</code> <p>Field(s) to include in the JSON output. Can take either a string or set of strings.</p> <code>None</code> <code>exclude</code> <code>IncEx</code> <p>Field(s) to exclude from the JSON output. Can take either a string or set of strings.</p> <code>None</code> <code>by_alias</code> <code>bool</code> <p>Whether to serialize using field aliases.</p> <code>False</code> <code>exclude_unset</code> <code>bool</code> <p>Whether to exclude fields that have not been explicitly set.</p> <code>False</code> <code>exclude_defaults</code> <code>bool</code> <p>Whether to exclude fields that have the default value.</p> <code>False</code> <code>exclude_none</code> <code>bool</code> <p>Whether to exclude fields that have a value of <code>None</code>.</p> <code>False</code> <code>round_trip</code> <code>bool</code> <p>Whether to use serialization/deserialization between JSON and class instance.</p> <code>False</code> <code>warnings</code> <code>bool</code> <p>Whether to show any warnings that occurred during serialization.</p> <code>True</code> <p>Returns:</p> Type Description <code>str</code> <p>A JSON string representation of the model.</p> Source code in <code>src/anthropic/_models.py</code> <pre><code>@override\ndef model_dump_json(\n    self,\n    *,\n    indent: int | None = None,\n    include: IncEx = None,\n    exclude: IncEx = None,\n    by_alias: bool = False,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    round_trip: bool = False,\n    warnings: bool = True,\n) -&gt; str:\n    \"\"\"Usage docs: https://docs.pydantic.dev/2.4/concepts/serialization/#modelmodel_dump_json\n\n    Generates a JSON representation of the model using Pydantic's `to_json` method.\n\n    Args:\n        indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n        include: Field(s) to include in the JSON output. Can take either a string or set of strings.\n        exclude: Field(s) to exclude from the JSON output. Can take either a string or set of strings.\n        by_alias: Whether to serialize using field aliases.\n        exclude_unset: Whether to exclude fields that have not been explicitly set.\n        exclude_defaults: Whether to exclude fields that have the default value.\n        exclude_none: Whether to exclude fields that have a value of `None`.\n        round_trip: Whether to use serialization/deserialization between JSON and class instance.\n        warnings: Whether to show any warnings that occurred during serialization.\n\n    Returns:\n        A JSON string representation of the model.\n    \"\"\"\n    if round_trip != False:\n        raise ValueError(\"round_trip is only supported in Pydantic v2\")\n    if warnings != True:\n        raise ValueError(\"warnings is only supported in Pydantic v2\")\n    return super().json(  # type: ignore[reportDeprecated]\n        indent=indent,\n        include=include,\n        exclude=exclude,\n        by_alias=by_alias,\n        exclude_unset=exclude_unset,\n        exclude_defaults=exclude_defaults,\n        exclude_none=exclude_none,\n    )\n</code></pre>"},{"location":"_models/#_models.BaseModel.to_dict","title":"<code>to_dict(*, mode='python', use_api_names=True, exclude_unset=True, exclude_defaults=False, exclude_none=False, warnings=True)</code>","text":"<p>Recursively generate a dictionary representation of the model, optionally specifying which fields to include or exclude.</p> <p>By default, fields that were not set by the API will not be included, and keys will match the API response, not the property names from the model.</p> <p>For example, if the API responds with <code>\"fooBar\": true</code> but we've defined a <code>foo_bar: bool</code> property, the output will use the <code>\"fooBar\"</code> key (unless <code>use_api_names=False</code> is passed).</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>Literal['json', 'python']</code> <p>If mode is 'json', the dictionary will only contain JSON serializable types. e.g. <code>datetime</code> will be turned into a string, <code>\"2024-3-22T18:11:19.117000Z\"</code>. If mode is 'python', the dictionary may contain any Python objects. e.g. <code>datetime(2024, 3, 22)</code></p> <code>'python'</code> <code>use_api_names</code> <code>bool</code> <p>Whether to use the key that the API responded with or the property name. Defaults to <code>True</code>.</p> <code>True</code> <code>exclude_unset</code> <code>bool</code> <p>Whether to exclude fields that have not been explicitly set.</p> <code>True</code> <code>exclude_defaults</code> <code>bool</code> <p>Whether to exclude fields that are set to their default value from the output.</p> <code>False</code> <code>exclude_none</code> <code>bool</code> <p>Whether to exclude fields that have a value of <code>None</code> from the output.</p> <code>False</code> <code>warnings</code> <code>bool</code> <p>Whether to log warnings when invalid fields are encountered. This is only supported in Pydantic v2.</p> <code>True</code> Source code in <code>src/anthropic/_models.py</code> <pre><code>def to_dict(\n    self,\n    *,\n    mode: Literal[\"json\", \"python\"] = \"python\",\n    use_api_names: bool = True,\n    exclude_unset: bool = True,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    warnings: bool = True,\n) -&gt; dict[str, object]:\n    \"\"\"Recursively generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n\n    By default, fields that were not set by the API will not be included,\n    and keys will match the API response, *not* the property names from the model.\n\n    For example, if the API responds with `\"fooBar\": true` but we've defined a `foo_bar: bool` property,\n    the output will use the `\"fooBar\"` key (unless `use_api_names=False` is passed).\n\n    Args:\n        mode:\n            If mode is 'json', the dictionary will only contain JSON serializable types. e.g. `datetime` will be turned into a string, `\"2024-3-22T18:11:19.117000Z\"`.\n            If mode is 'python', the dictionary may contain any Python objects. e.g. `datetime(2024, 3, 22)`\n\n        use_api_names: Whether to use the key that the API responded with or the property name. Defaults to `True`.\n        exclude_unset: Whether to exclude fields that have not been explicitly set.\n        exclude_defaults: Whether to exclude fields that are set to their default value from the output.\n        exclude_none: Whether to exclude fields that have a value of `None` from the output.\n        warnings: Whether to log warnings when invalid fields are encountered. This is only supported in Pydantic v2.\n    \"\"\"\n    return self.model_dump(\n        mode=mode,\n        by_alias=use_api_names,\n        exclude_unset=exclude_unset,\n        exclude_defaults=exclude_defaults,\n        exclude_none=exclude_none,\n        warnings=warnings,\n    )\n</code></pre>"},{"location":"_models/#_models.BaseModel.to_json","title":"<code>to_json(*, indent=2, use_api_names=True, exclude_unset=True, exclude_defaults=False, exclude_none=False, warnings=True)</code>","text":"<p>Generates a JSON string representing this model as it would be received from or sent to the API (but with indentation).</p> <p>By default, fields that were not set by the API will not be included, and keys will match the API response, not the property names from the model.</p> <p>For example, if the API responds with <code>\"fooBar\": true</code> but we've defined a <code>foo_bar: bool</code> property, the output will use the <code>\"fooBar\"</code> key (unless <code>use_api_names=False</code> is passed).</p> <p>Parameters:</p> Name Type Description Default <code>indent</code> <code>int | None</code> <p>Indentation to use in the JSON output. If <code>None</code> is passed, the output will be compact. Defaults to <code>2</code></p> <code>2</code> <code>use_api_names</code> <code>bool</code> <p>Whether to use the key that the API responded with or the property name. Defaults to <code>True</code>.</p> <code>True</code> <code>exclude_unset</code> <code>bool</code> <p>Whether to exclude fields that have not been explicitly set.</p> <code>True</code> <code>exclude_defaults</code> <code>bool</code> <p>Whether to exclude fields that have the default value.</p> <code>False</code> <code>exclude_none</code> <code>bool</code> <p>Whether to exclude fields that have a value of <code>None</code>.</p> <code>False</code> <code>warnings</code> <code>bool</code> <p>Whether to show any warnings that occurred during serialization. This is only supported in Pydantic v2.</p> <code>True</code> Source code in <code>src/anthropic/_models.py</code> <pre><code>def to_json(\n    self,\n    *,\n    indent: int | None = 2,\n    use_api_names: bool = True,\n    exclude_unset: bool = True,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    warnings: bool = True,\n) -&gt; str:\n    \"\"\"Generates a JSON string representing this model as it would be received from or sent to the API (but with indentation).\n\n    By default, fields that were not set by the API will not be included,\n    and keys will match the API response, *not* the property names from the model.\n\n    For example, if the API responds with `\"fooBar\": true` but we've defined a `foo_bar: bool` property,\n    the output will use the `\"fooBar\"` key (unless `use_api_names=False` is passed).\n\n    Args:\n        indent: Indentation to use in the JSON output. If `None` is passed, the output will be compact. Defaults to `2`\n        use_api_names: Whether to use the key that the API responded with or the property name. Defaults to `True`.\n        exclude_unset: Whether to exclude fields that have not been explicitly set.\n        exclude_defaults: Whether to exclude fields that have the default value.\n        exclude_none: Whether to exclude fields that have a value of `None`.\n        warnings: Whether to show any warnings that occurred during serialization. This is only supported in Pydantic v2.\n    \"\"\"\n    return self.model_dump_json(\n        indent=indent,\n        by_alias=use_api_names,\n        exclude_unset=exclude_unset,\n        exclude_defaults=exclude_defaults,\n        exclude_none=exclude_none,\n        warnings=warnings,\n    )\n</code></pre>"},{"location":"_models/#_models.DiscriminatorDetails","title":"<code>DiscriminatorDetails</code>","text":"Source code in <code>src/anthropic/_models.py</code> <pre><code>class DiscriminatorDetails:\n    field_name: str\n    \"\"\"The name of the discriminator field in the variant class, e.g.\n\n    ```py\n    class Foo(BaseModel):\n        type: Literal['foo']\n    ```\n\n    Will result in field_name='type'\n    \"\"\"\n\n    field_alias_from: str | None\n    \"\"\"The name of the discriminator field in the API response, e.g.\n\n    ```py\n    class Foo(BaseModel):\n        type: Literal['foo'] = Field(alias='type_from_api')\n    ```\n\n    Will result in field_alias_from='type_from_api'\n    \"\"\"\n\n    mapping: dict[str, type]\n    \"\"\"Mapping of discriminator value to variant type, e.g.\n\n    {'foo': FooVariant, 'bar': BarVariant}\n    \"\"\"\n\n    def __init__(\n        self,\n        *,\n        mapping: dict[str, type],\n        discriminator_field: str,\n        discriminator_alias: str | None,\n    ) -&gt; None:\n        self.mapping = mapping\n        self.field_name = discriminator_field\n        self.field_alias_from = discriminator_alias\n</code></pre>"},{"location":"_models/#_models.DiscriminatorDetails.field_alias_from","title":"<code>field_alias_from: str | None = discriminator_alias</code>  <code>instance-attribute</code>","text":"<p>The name of the discriminator field in the API response, e.g.</p> <pre><code>class Foo(BaseModel):\n    type: Literal['foo'] = Field(alias='type_from_api')\n</code></pre> <p>Will result in field_alias_from='type_from_api'</p>"},{"location":"_models/#_models.DiscriminatorDetails.field_name","title":"<code>field_name: str = discriminator_field</code>  <code>instance-attribute</code>","text":"<p>The name of the discriminator field in the variant class, e.g.</p> <pre><code>class Foo(BaseModel):\n    type: Literal['foo']\n</code></pre> <p>Will result in field_name='type'</p>"},{"location":"_models/#_models.DiscriminatorDetails.mapping","title":"<code>mapping: dict[str, type] = mapping</code>  <code>instance-attribute</code>","text":"<p>Mapping of discriminator value to variant type, e.g.</p> <p>{'foo': FooVariant, 'bar': BarVariant}</p>"},{"location":"_models/#_models.RootModel","title":"<code>RootModel</code>","text":"<p>             Bases: <code>GenericModel</code>, <code>Generic[_T]</code></p> <p>Used as a placeholder to easily convert runtime types to a Pydantic format to provide validation.</p> <p>For example:</p> <pre><code>validated = RootModel[int](__root__=\"5\").__root__\n# validated: 5\n</code></pre> Source code in <code>src/anthropic/_models.py</code> <pre><code>class RootModel(GenericModel, Generic[_T]):\n    \"\"\"Used as a placeholder to easily convert runtime types to a Pydantic format\n    to provide validation.\n\n    For example:\n    ```py\n    validated = RootModel[int](__root__=\"5\").__root__\n    # validated: 5\n    ```\n    \"\"\"\n\n    __root__: _T\n</code></pre>"},{"location":"_models/#_models.construct_type","title":"<code>construct_type(*, value, type_)</code>","text":"<p>Loose coercion to the expected type with construction of nested values.</p> <p>If the given value does not match the expected type then it is returned as-is.</p> Source code in <code>src/anthropic/_models.py</code> <pre><code>def construct_type(*, value: object, type_: object) -&gt; object:\n    \"\"\"Loose coercion to the expected type with construction of nested values.\n\n    If the given value does not match the expected type then it is returned as-is.\n    \"\"\"\n    # we allow `object` as the input type because otherwise, passing things like\n    # `Literal['value']` will be reported as a type error by type checkers\n    type_ = cast(\"type[object]\", type_)\n\n    # unwrap `Annotated[T, ...]` -&gt; `T`\n    if is_annotated_type(type_):\n        meta: tuple[Any, ...] = get_args(type_)[1:]\n        type_ = extract_type_arg(type_, 0)\n    else:\n        meta = tuple()\n\n    # we need to use the origin class for any types that are subscripted generics\n    # e.g. Dict[str, object]\n    origin = get_origin(type_) or type_\n    args = get_args(type_)\n\n    if is_union(origin):\n        try:\n            return validate_type(type_=cast(\"type[object]\", type_), value=value)\n        except Exception:\n            pass\n\n        # if the type is a discriminated union then we want to construct the right variant\n        # in the union, even if the data doesn't match exactly, otherwise we'd break code\n        # that relies on the constructed class types, e.g.\n        #\n        # class FooType:\n        #   kind: Literal['foo']\n        #   value: str\n        #\n        # class BarType:\n        #   kind: Literal['bar']\n        #   value: int\n        #\n        # without this block, if the data we get is something like `{'kind': 'bar', 'value': 'foo'}` then\n        # we'd end up constructing `FooType` when it should be `BarType`.\n        discriminator = _build_discriminated_union_meta(union=type_, meta_annotations=meta)\n        if discriminator and is_mapping(value):\n            variant_value = value.get(discriminator.field_alias_from or discriminator.field_name)\n            if variant_value and isinstance(variant_value, str):\n                variant_type = discriminator.mapping.get(variant_value)\n                if variant_type:\n                    return construct_type(type_=variant_type, value=value)\n\n        # if the data is not valid, use the first variant that doesn't fail while deserializing\n        for variant in args:\n            try:\n                return construct_type(value=value, type_=variant)\n            except Exception:\n                continue\n\n        raise RuntimeError(f\"Could not convert data into a valid instance of {type_}\")\n\n    if origin == dict:\n        if not is_mapping(value):\n            return value\n\n        _, items_type = get_args(type_)  # Dict[_, items_type]\n        return {key: construct_type(value=item, type_=items_type) for key, item in value.items()}\n\n    if not is_literal_type(type_) and (issubclass(origin, BaseModel) or issubclass(origin, GenericModel)):\n        if is_list(value):\n            return [cast(Any, type_).construct(**entry) if is_mapping(entry) else entry for entry in value]\n\n        if is_mapping(value):\n            if issubclass(type_, BaseModel):\n                return type_.construct(**value)  # type: ignore[arg-type]\n\n            return cast(Any, type_).construct(**value)\n\n    if origin == list:\n        if not is_list(value):\n            return value\n\n        inner_type = args[0]  # List[inner_type]\n        return [construct_type(value=entry, type_=inner_type) for entry in value]\n\n    if origin == float:\n        if isinstance(value, int):\n            coerced = float(value)\n            if coerced != value:\n                return value\n            return coerced\n\n        return value\n\n    if type_ == datetime:\n        try:\n            return parse_datetime(value)  # type: ignore\n        except Exception:\n            return value\n\n    if type_ == date:\n        try:\n            return parse_date(value)  # type: ignore\n        except Exception:\n            return value\n\n    return value\n</code></pre>"},{"location":"_models/#_models.is_basemodel","title":"<code>is_basemodel(type_)</code>","text":"<p>Returns whether or not the given type is either a <code>BaseModel</code> or a union of <code>BaseModel</code></p> Source code in <code>src/anthropic/_models.py</code> <pre><code>def is_basemodel(type_: type) -&gt; bool:\n    \"\"\"Returns whether or not the given type is either a `BaseModel` or a union of `BaseModel`\"\"\"\n    if is_union(type_):\n        for variant in get_args(type_):\n            if is_basemodel(variant):\n                return True\n\n        return False\n\n    return is_basemodel_type(type_)\n</code></pre>"},{"location":"_models/#_models.validate_type","title":"<code>validate_type(*, type_, value)</code>","text":"<p>Strict validation that the given value matches the expected type</p> Source code in <code>src/anthropic/_models.py</code> <pre><code>def validate_type(*, type_: type[_T], value: object) -&gt; _T:\n    \"\"\"Strict validation that the given value matches the expected type\"\"\"\n    if inspect.isclass(type_) and issubclass(type_, pydantic.BaseModel):\n        return cast(_T, parse_obj(type_, value))\n\n    return cast(_T, _validate_non_model_type(type_=type_, value=value))\n</code></pre>"},{"location":"_response/","title":"_response","text":""},{"location":"_response/#_response","title":"<code>_response</code>","text":""},{"location":"_response/#_response.APIResponse","title":"<code>APIResponse</code>","text":"<p>             Bases: <code>BaseAPIResponse[R]</code></p> Source code in <code>src/anthropic/_response.py</code> <pre><code>class APIResponse(BaseAPIResponse[R]):\n    @overload\n    def parse(self, *, to: type[_T]) -&gt; _T:\n        ...\n\n    @overload\n    def parse(self) -&gt; R:\n        ...\n\n    def parse(self, *, to: type[_T] | None = None) -&gt; R | _T:\n        \"\"\"Returns the rich python representation of this response's data.\n\n        For lower-level control, see `.read()`, `.json()`, `.iter_bytes()`.\n\n        You can customise the type that the response is parsed into through\n        the `to` argument, e.g.\n\n        ```py\n        from anthropic import BaseModel\n\n\n        class MyModel(BaseModel):\n            foo: str\n\n\n        obj = response.parse(to=MyModel)\n        print(obj.foo)\n        ```\n\n        We support parsing:\n          - `BaseModel`\n          - `dict`\n          - `list`\n          - `Union`\n          - `str`\n          - `int`\n          - `float`\n          - `httpx.Response`\n        \"\"\"\n        cache_key = to if to is not None else self._cast_to\n        cached = self._parsed_by_type.get(cache_key)\n        if cached is not None:\n            return cached  # type: ignore[no-any-return]\n\n        if not self._is_sse_stream:\n            self.read()\n\n        parsed = self._parse(to=to)\n        if is_given(self._options.post_parser):\n            parsed = self._options.post_parser(parsed)\n\n        self._parsed_by_type[cache_key] = parsed\n        return parsed\n\n    def read(self) -&gt; bytes:\n        \"\"\"Read and return the binary response content.\"\"\"\n        try:\n            return self.http_response.read()\n        except httpx.StreamConsumed as exc:\n            # The default error raised by httpx isn't very\n            # helpful in our case so we re-raise it with\n            # a different error message.\n            raise StreamAlreadyConsumed() from exc\n\n    def text(self) -&gt; str:\n        \"\"\"Read and decode the response content into a string.\"\"\"\n        self.read()\n        return self.http_response.text\n\n    def json(self) -&gt; object:\n        \"\"\"Read and decode the JSON response content.\"\"\"\n        self.read()\n        return self.http_response.json()\n\n    def close(self) -&gt; None:\n        \"\"\"Close the response and release the connection.\n\n        Automatically called if the response body is read to completion.\n        \"\"\"\n        self.http_response.close()\n\n    def iter_bytes(self, chunk_size: int | None = None) -&gt; Iterator[bytes]:\n        \"\"\"\n        A byte-iterator over the decoded response content.\n\n        This automatically handles gzip, deflate and brotli encoded responses.\n        \"\"\"\n        for chunk in self.http_response.iter_bytes(chunk_size):\n            yield chunk\n\n    def iter_text(self, chunk_size: int | None = None) -&gt; Iterator[str]:\n        \"\"\"A str-iterator over the decoded response content\n        that handles both gzip, deflate, etc but also detects the content's\n        string encoding.\n        \"\"\"\n        for chunk in self.http_response.iter_text(chunk_size):\n            yield chunk\n\n    def iter_lines(self) -&gt; Iterator[str]:\n        \"\"\"Like `iter_text()` but will only yield chunks for each line\"\"\"\n        for chunk in self.http_response.iter_lines():\n            yield chunk\n</code></pre>"},{"location":"_response/#_response.APIResponse.close","title":"<code>close()</code>","text":"<p>Close the response and release the connection.</p> <p>Automatically called if the response body is read to completion.</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the response and release the connection.\n\n    Automatically called if the response body is read to completion.\n    \"\"\"\n    self.http_response.close()\n</code></pre>"},{"location":"_response/#_response.APIResponse.iter_bytes","title":"<code>iter_bytes(chunk_size=None)</code>","text":"<p>A byte-iterator over the decoded response content.</p> <p>This automatically handles gzip, deflate and brotli encoded responses.</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>def iter_bytes(self, chunk_size: int | None = None) -&gt; Iterator[bytes]:\n    \"\"\"\n    A byte-iterator over the decoded response content.\n\n    This automatically handles gzip, deflate and brotli encoded responses.\n    \"\"\"\n    for chunk in self.http_response.iter_bytes(chunk_size):\n        yield chunk\n</code></pre>"},{"location":"_response/#_response.APIResponse.iter_lines","title":"<code>iter_lines()</code>","text":"<p>Like <code>iter_text()</code> but will only yield chunks for each line</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>def iter_lines(self) -&gt; Iterator[str]:\n    \"\"\"Like `iter_text()` but will only yield chunks for each line\"\"\"\n    for chunk in self.http_response.iter_lines():\n        yield chunk\n</code></pre>"},{"location":"_response/#_response.APIResponse.iter_text","title":"<code>iter_text(chunk_size=None)</code>","text":"<p>A str-iterator over the decoded response content that handles both gzip, deflate, etc but also detects the content's string encoding.</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>def iter_text(self, chunk_size: int | None = None) -&gt; Iterator[str]:\n    \"\"\"A str-iterator over the decoded response content\n    that handles both gzip, deflate, etc but also detects the content's\n    string encoding.\n    \"\"\"\n    for chunk in self.http_response.iter_text(chunk_size):\n        yield chunk\n</code></pre>"},{"location":"_response/#_response.APIResponse.json","title":"<code>json()</code>","text":"<p>Read and decode the JSON response content.</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>def json(self) -&gt; object:\n    \"\"\"Read and decode the JSON response content.\"\"\"\n    self.read()\n    return self.http_response.json()\n</code></pre>"},{"location":"_response/#_response.APIResponse.parse","title":"<code>parse(*, to=None)</code>","text":"<p>Returns the rich python representation of this response's data.</p> <p>For lower-level control, see <code>.read()</code>, <code>.json()</code>, <code>.iter_bytes()</code>.</p> <p>You can customise the type that the response is parsed into through the <code>to</code> argument, e.g.</p> <pre><code>from anthropic import BaseModel\n\n\nclass MyModel(BaseModel):\n    foo: str\n\n\nobj = response.parse(to=MyModel)\nprint(obj.foo)\n</code></pre> We support parsing <ul> <li><code>BaseModel</code></li> <li><code>dict</code></li> <li><code>list</code></li> <li><code>Union</code></li> <li><code>str</code></li> <li><code>int</code></li> <li><code>float</code></li> <li><code>httpx.Response</code></li> </ul> Source code in <code>src/anthropic/_response.py</code> <pre><code>def parse(self, *, to: type[_T] | None = None) -&gt; R | _T:\n    \"\"\"Returns the rich python representation of this response's data.\n\n    For lower-level control, see `.read()`, `.json()`, `.iter_bytes()`.\n\n    You can customise the type that the response is parsed into through\n    the `to` argument, e.g.\n\n    ```py\n    from anthropic import BaseModel\n\n\n    class MyModel(BaseModel):\n        foo: str\n\n\n    obj = response.parse(to=MyModel)\n    print(obj.foo)\n    ```\n\n    We support parsing:\n      - `BaseModel`\n      - `dict`\n      - `list`\n      - `Union`\n      - `str`\n      - `int`\n      - `float`\n      - `httpx.Response`\n    \"\"\"\n    cache_key = to if to is not None else self._cast_to\n    cached = self._parsed_by_type.get(cache_key)\n    if cached is not None:\n        return cached  # type: ignore[no-any-return]\n\n    if not self._is_sse_stream:\n        self.read()\n\n    parsed = self._parse(to=to)\n    if is_given(self._options.post_parser):\n        parsed = self._options.post_parser(parsed)\n\n    self._parsed_by_type[cache_key] = parsed\n    return parsed\n</code></pre>"},{"location":"_response/#_response.APIResponse.read","title":"<code>read()</code>","text":"<p>Read and return the binary response content.</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>def read(self) -&gt; bytes:\n    \"\"\"Read and return the binary response content.\"\"\"\n    try:\n        return self.http_response.read()\n    except httpx.StreamConsumed as exc:\n        # The default error raised by httpx isn't very\n        # helpful in our case so we re-raise it with\n        # a different error message.\n        raise StreamAlreadyConsumed() from exc\n</code></pre>"},{"location":"_response/#_response.APIResponse.text","title":"<code>text()</code>","text":"<p>Read and decode the response content into a string.</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>def text(self) -&gt; str:\n    \"\"\"Read and decode the response content into a string.\"\"\"\n    self.read()\n    return self.http_response.text\n</code></pre>"},{"location":"_response/#_response.AsyncAPIResponse","title":"<code>AsyncAPIResponse</code>","text":"<p>             Bases: <code>BaseAPIResponse[R]</code></p> Source code in <code>src/anthropic/_response.py</code> <pre><code>class AsyncAPIResponse(BaseAPIResponse[R]):\n    @overload\n    async def parse(self, *, to: type[_T]) -&gt; _T:\n        ...\n\n    @overload\n    async def parse(self) -&gt; R:\n        ...\n\n    async def parse(self, *, to: type[_T] | None = None) -&gt; R | _T:\n        \"\"\"Returns the rich python representation of this response's data.\n\n        For lower-level control, see `.read()`, `.json()`, `.iter_bytes()`.\n\n        You can customise the type that the response is parsed into through\n        the `to` argument, e.g.\n\n        ```py\n        from anthropic import BaseModel\n\n\n        class MyModel(BaseModel):\n            foo: str\n\n\n        obj = response.parse(to=MyModel)\n        print(obj.foo)\n        ```\n\n        We support parsing:\n          - `BaseModel`\n          - `dict`\n          - `list`\n          - `Union`\n          - `str`\n          - `httpx.Response`\n        \"\"\"\n        cache_key = to if to is not None else self._cast_to\n        cached = self._parsed_by_type.get(cache_key)\n        if cached is not None:\n            return cached  # type: ignore[no-any-return]\n\n        if not self._is_sse_stream:\n            await self.read()\n\n        parsed = self._parse(to=to)\n        if is_given(self._options.post_parser):\n            parsed = self._options.post_parser(parsed)\n\n        self._parsed_by_type[cache_key] = parsed\n        return parsed\n\n    async def read(self) -&gt; bytes:\n        \"\"\"Read and return the binary response content.\"\"\"\n        try:\n            return await self.http_response.aread()\n        except httpx.StreamConsumed as exc:\n            # the default error raised by httpx isn't very\n            # helpful in our case so we re-raise it with\n            # a different error message\n            raise StreamAlreadyConsumed() from exc\n\n    async def text(self) -&gt; str:\n        \"\"\"Read and decode the response content into a string.\"\"\"\n        await self.read()\n        return self.http_response.text\n\n    async def json(self) -&gt; object:\n        \"\"\"Read and decode the JSON response content.\"\"\"\n        await self.read()\n        return self.http_response.json()\n\n    async def close(self) -&gt; None:\n        \"\"\"Close the response and release the connection.\n\n        Automatically called if the response body is read to completion.\n        \"\"\"\n        await self.http_response.aclose()\n\n    async def iter_bytes(self, chunk_size: int | None = None) -&gt; AsyncIterator[bytes]:\n        \"\"\"\n        A byte-iterator over the decoded response content.\n\n        This automatically handles gzip, deflate and brotli encoded responses.\n        \"\"\"\n        async for chunk in self.http_response.aiter_bytes(chunk_size):\n            yield chunk\n\n    async def iter_text(self, chunk_size: int | None = None) -&gt; AsyncIterator[str]:\n        \"\"\"A str-iterator over the decoded response content\n        that handles both gzip, deflate, etc but also detects the content's\n        string encoding.\n        \"\"\"\n        async for chunk in self.http_response.aiter_text(chunk_size):\n            yield chunk\n\n    async def iter_lines(self) -&gt; AsyncIterator[str]:\n        \"\"\"Like `iter_text()` but will only yield chunks for each line\"\"\"\n        async for chunk in self.http_response.aiter_lines():\n            yield chunk\n</code></pre>"},{"location":"_response/#_response.AsyncAPIResponse.close","title":"<code>close()</code>  <code>async</code>","text":"<p>Close the response and release the connection.</p> <p>Automatically called if the response body is read to completion.</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Close the response and release the connection.\n\n    Automatically called if the response body is read to completion.\n    \"\"\"\n    await self.http_response.aclose()\n</code></pre>"},{"location":"_response/#_response.AsyncAPIResponse.iter_bytes","title":"<code>iter_bytes(chunk_size=None)</code>  <code>async</code>","text":"<p>A byte-iterator over the decoded response content.</p> <p>This automatically handles gzip, deflate and brotli encoded responses.</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>async def iter_bytes(self, chunk_size: int | None = None) -&gt; AsyncIterator[bytes]:\n    \"\"\"\n    A byte-iterator over the decoded response content.\n\n    This automatically handles gzip, deflate and brotli encoded responses.\n    \"\"\"\n    async for chunk in self.http_response.aiter_bytes(chunk_size):\n        yield chunk\n</code></pre>"},{"location":"_response/#_response.AsyncAPIResponse.iter_lines","title":"<code>iter_lines()</code>  <code>async</code>","text":"<p>Like <code>iter_text()</code> but will only yield chunks for each line</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>async def iter_lines(self) -&gt; AsyncIterator[str]:\n    \"\"\"Like `iter_text()` but will only yield chunks for each line\"\"\"\n    async for chunk in self.http_response.aiter_lines():\n        yield chunk\n</code></pre>"},{"location":"_response/#_response.AsyncAPIResponse.iter_text","title":"<code>iter_text(chunk_size=None)</code>  <code>async</code>","text":"<p>A str-iterator over the decoded response content that handles both gzip, deflate, etc but also detects the content's string encoding.</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>async def iter_text(self, chunk_size: int | None = None) -&gt; AsyncIterator[str]:\n    \"\"\"A str-iterator over the decoded response content\n    that handles both gzip, deflate, etc but also detects the content's\n    string encoding.\n    \"\"\"\n    async for chunk in self.http_response.aiter_text(chunk_size):\n        yield chunk\n</code></pre>"},{"location":"_response/#_response.AsyncAPIResponse.json","title":"<code>json()</code>  <code>async</code>","text":"<p>Read and decode the JSON response content.</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>async def json(self) -&gt; object:\n    \"\"\"Read and decode the JSON response content.\"\"\"\n    await self.read()\n    return self.http_response.json()\n</code></pre>"},{"location":"_response/#_response.AsyncAPIResponse.parse","title":"<code>parse(*, to=None)</code>  <code>async</code>","text":"<p>Returns the rich python representation of this response's data.</p> <p>For lower-level control, see <code>.read()</code>, <code>.json()</code>, <code>.iter_bytes()</code>.</p> <p>You can customise the type that the response is parsed into through the <code>to</code> argument, e.g.</p> <pre><code>from anthropic import BaseModel\n\n\nclass MyModel(BaseModel):\n    foo: str\n\n\nobj = response.parse(to=MyModel)\nprint(obj.foo)\n</code></pre> We support parsing <ul> <li><code>BaseModel</code></li> <li><code>dict</code></li> <li><code>list</code></li> <li><code>Union</code></li> <li><code>str</code></li> <li><code>httpx.Response</code></li> </ul> Source code in <code>src/anthropic/_response.py</code> <pre><code>async def parse(self, *, to: type[_T] | None = None) -&gt; R | _T:\n    \"\"\"Returns the rich python representation of this response's data.\n\n    For lower-level control, see `.read()`, `.json()`, `.iter_bytes()`.\n\n    You can customise the type that the response is parsed into through\n    the `to` argument, e.g.\n\n    ```py\n    from anthropic import BaseModel\n\n\n    class MyModel(BaseModel):\n        foo: str\n\n\n    obj = response.parse(to=MyModel)\n    print(obj.foo)\n    ```\n\n    We support parsing:\n      - `BaseModel`\n      - `dict`\n      - `list`\n      - `Union`\n      - `str`\n      - `httpx.Response`\n    \"\"\"\n    cache_key = to if to is not None else self._cast_to\n    cached = self._parsed_by_type.get(cache_key)\n    if cached is not None:\n        return cached  # type: ignore[no-any-return]\n\n    if not self._is_sse_stream:\n        await self.read()\n\n    parsed = self._parse(to=to)\n    if is_given(self._options.post_parser):\n        parsed = self._options.post_parser(parsed)\n\n    self._parsed_by_type[cache_key] = parsed\n    return parsed\n</code></pre>"},{"location":"_response/#_response.AsyncAPIResponse.read","title":"<code>read()</code>  <code>async</code>","text":"<p>Read and return the binary response content.</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>async def read(self) -&gt; bytes:\n    \"\"\"Read and return the binary response content.\"\"\"\n    try:\n        return await self.http_response.aread()\n    except httpx.StreamConsumed as exc:\n        # the default error raised by httpx isn't very\n        # helpful in our case so we re-raise it with\n        # a different error message\n        raise StreamAlreadyConsumed() from exc\n</code></pre>"},{"location":"_response/#_response.AsyncAPIResponse.text","title":"<code>text()</code>  <code>async</code>","text":"<p>Read and decode the response content into a string.</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>async def text(self) -&gt; str:\n    \"\"\"Read and decode the response content into a string.\"\"\"\n    await self.read()\n    return self.http_response.text\n</code></pre>"},{"location":"_response/#_response.AsyncBinaryAPIResponse","title":"<code>AsyncBinaryAPIResponse</code>","text":"<p>             Bases: <code>AsyncAPIResponse[bytes]</code></p> <p>Subclass of APIResponse providing helpers for dealing with binary data.</p> <p>Note: If you want to stream the response data instead of eagerly reading it all at once then you should use <code>.with_streaming_response</code> when making the API request, e.g. <code>.with_streaming_response.get_binary_response()</code></p> Source code in <code>src/anthropic/_response.py</code> <pre><code>class AsyncBinaryAPIResponse(AsyncAPIResponse[bytes]):\n    \"\"\"Subclass of APIResponse providing helpers for dealing with binary data.\n\n    Note: If you want to stream the response data instead of eagerly reading it\n    all at once then you should use `.with_streaming_response` when making\n    the API request, e.g. `.with_streaming_response.get_binary_response()`\n    \"\"\"\n\n    async def write_to_file(\n        self,\n        file: str | os.PathLike[str],\n    ) -&gt; None:\n        \"\"\"Write the output to the given file.\n\n        Accepts a filename or any path-like object, e.g. pathlib.Path\n\n        Note: if you want to stream the data to the file instead of writing\n        all at once then you should use `.with_streaming_response` when making\n        the API request, e.g. `.with_streaming_response.get_binary_response()`\n        \"\"\"\n        path = anyio.Path(file)\n        async with await path.open(mode=\"wb\") as f:\n            async for data in self.iter_bytes():\n                await f.write(data)\n</code></pre>"},{"location":"_response/#_response.AsyncBinaryAPIResponse.write_to_file","title":"<code>write_to_file(file)</code>  <code>async</code>","text":"<p>Write the output to the given file.</p> <p>Accepts a filename or any path-like object, e.g. pathlib.Path</p> <p>Note: if you want to stream the data to the file instead of writing all at once then you should use <code>.with_streaming_response</code> when making the API request, e.g. <code>.with_streaming_response.get_binary_response()</code></p> Source code in <code>src/anthropic/_response.py</code> <pre><code>async def write_to_file(\n    self,\n    file: str | os.PathLike[str],\n) -&gt; None:\n    \"\"\"Write the output to the given file.\n\n    Accepts a filename or any path-like object, e.g. pathlib.Path\n\n    Note: if you want to stream the data to the file instead of writing\n    all at once then you should use `.with_streaming_response` when making\n    the API request, e.g. `.with_streaming_response.get_binary_response()`\n    \"\"\"\n    path = anyio.Path(file)\n    async with await path.open(mode=\"wb\") as f:\n        async for data in self.iter_bytes():\n            await f.write(data)\n</code></pre>"},{"location":"_response/#_response.AsyncResponseContextManager","title":"<code>AsyncResponseContextManager</code>","text":"<p>             Bases: <code>Generic[_AsyncAPIResponseT]</code></p> <p>Context manager for ensuring that a request is not made until it is entered and that the response will always be closed when the context manager exits</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>class AsyncResponseContextManager(Generic[_AsyncAPIResponseT]):\n    \"\"\"Context manager for ensuring that a request is not made\n    until it is entered and that the response will always be closed\n    when the context manager exits\n    \"\"\"\n\n    def __init__(self, api_request: Awaitable[_AsyncAPIResponseT]) -&gt; None:\n        self._api_request = api_request\n        self.__response: _AsyncAPIResponseT | None = None\n\n    async def __aenter__(self) -&gt; _AsyncAPIResponseT:\n        self.__response = await self._api_request\n        return self.__response\n\n    async def __aexit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc: BaseException | None,\n        exc_tb: TracebackType | None,\n    ) -&gt; None:\n        if self.__response is not None:\n            await self.__response.close()\n</code></pre>"},{"location":"_response/#_response.AsyncStreamedBinaryAPIResponse","title":"<code>AsyncStreamedBinaryAPIResponse</code>","text":"<p>             Bases: <code>AsyncAPIResponse[bytes]</code></p> Source code in <code>src/anthropic/_response.py</code> <pre><code>class AsyncStreamedBinaryAPIResponse(AsyncAPIResponse[bytes]):\n    async def stream_to_file(\n        self,\n        file: str | os.PathLike[str],\n        *,\n        chunk_size: int | None = None,\n    ) -&gt; None:\n        \"\"\"Streams the output to the given file.\n\n        Accepts a filename or any path-like object, e.g. pathlib.Path\n        \"\"\"\n        path = anyio.Path(file)\n        async with await path.open(mode=\"wb\") as f:\n            async for data in self.iter_bytes(chunk_size):\n                await f.write(data)\n</code></pre>"},{"location":"_response/#_response.AsyncStreamedBinaryAPIResponse.stream_to_file","title":"<code>stream_to_file(file, *, chunk_size=None)</code>  <code>async</code>","text":"<p>Streams the output to the given file.</p> <p>Accepts a filename or any path-like object, e.g. pathlib.Path</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>async def stream_to_file(\n    self,\n    file: str | os.PathLike[str],\n    *,\n    chunk_size: int | None = None,\n) -&gt; None:\n    \"\"\"Streams the output to the given file.\n\n    Accepts a filename or any path-like object, e.g. pathlib.Path\n    \"\"\"\n    path = anyio.Path(file)\n    async with await path.open(mode=\"wb\") as f:\n        async for data in self.iter_bytes(chunk_size):\n            await f.write(data)\n</code></pre>"},{"location":"_response/#_response.BaseAPIResponse","title":"<code>BaseAPIResponse</code>","text":"<p>             Bases: <code>Generic[R]</code></p> Source code in <code>src/anthropic/_response.py</code> <pre><code>class BaseAPIResponse(Generic[R]):\n    _cast_to: type[R]\n    _client: BaseClient[Any, Any]\n    _parsed_by_type: dict[type[Any], Any]\n    _is_sse_stream: bool\n    _stream_cls: type[Stream[Any]] | type[AsyncStream[Any]] | None\n    _options: FinalRequestOptions\n\n    http_response: httpx.Response\n\n    def __init__(\n        self,\n        *,\n        raw: httpx.Response,\n        cast_to: type[R],\n        client: BaseClient[Any, Any],\n        stream: bool,\n        stream_cls: type[Stream[Any]] | type[AsyncStream[Any]] | None,\n        options: FinalRequestOptions,\n    ) -&gt; None:\n        self._cast_to = cast_to\n        self._client = client\n        self._parsed_by_type = {}\n        self._is_sse_stream = stream\n        self._stream_cls = stream_cls\n        self._options = options\n        self.http_response = raw\n\n    @property\n    def headers(self) -&gt; httpx.Headers:\n        return self.http_response.headers\n\n    @property\n    def http_request(self) -&gt; httpx.Request:\n        \"\"\"Returns the httpx Request instance associated with the current response.\"\"\"\n        return self.http_response.request\n\n    @property\n    def status_code(self) -&gt; int:\n        return self.http_response.status_code\n\n    @property\n    def url(self) -&gt; httpx.URL:\n        \"\"\"Returns the URL for which the request was made.\"\"\"\n        return self.http_response.url\n\n    @property\n    def method(self) -&gt; str:\n        return self.http_request.method\n\n    @property\n    def http_version(self) -&gt; str:\n        return self.http_response.http_version\n\n    @property\n    def elapsed(self) -&gt; datetime.timedelta:\n        \"\"\"The time taken for the complete request/response cycle to complete.\"\"\"\n        return self.http_response.elapsed\n\n    @property\n    def is_closed(self) -&gt; bool:\n        \"\"\"Whether or not the response body has been closed.\n\n        If this is False then there is response data that has not been read yet.\n        You must either fully consume the response body or call `.close()`\n        before discarding the response to prevent resource leaks.\n        \"\"\"\n        return self.http_response.is_closed\n\n    @override\n    def __repr__(self) -&gt; str:\n        return (\n            f\"&lt;{self.__class__.__name__} [{self.status_code} {self.http_response.reason_phrase}] type={self._cast_to}&gt;\"\n        )\n\n    def _parse(self, *, to: type[_T] | None = None) -&gt; R | _T:\n        # unwrap `Annotated[T, ...]` -&gt; `T`\n        if to and is_annotated_type(to):\n            to = extract_type_arg(to, 0)\n\n        if self._is_sse_stream:\n            if to:\n                if not is_stream_class_type(to):\n                    raise TypeError(f\"Expected custom parse type to be a subclass of {Stream} or {AsyncStream}\")\n\n                return cast(\n                    _T,\n                    to(\n                        cast_to=extract_stream_chunk_type(\n                            to,\n                            failure_message=\"Expected custom stream type to be passed with a type argument, e.g. Stream[ChunkType]\",\n                        ),\n                        response=self.http_response,\n                        client=cast(Any, self._client),\n                    ),\n                )\n\n            if self._stream_cls:\n                return cast(\n                    R,\n                    self._stream_cls(\n                        cast_to=extract_stream_chunk_type(self._stream_cls),\n                        response=self.http_response,\n                        client=cast(Any, self._client),\n                    ),\n                )\n\n            stream_cls = cast(\"type[Stream[Any]] | type[AsyncStream[Any]] | None\", self._client._default_stream_cls)\n            if stream_cls is None:\n                raise MissingStreamClassError()\n\n            return cast(\n                R,\n                stream_cls(\n                    cast_to=self._cast_to,\n                    response=self.http_response,\n                    client=cast(Any, self._client),\n                ),\n            )\n\n        cast_to = to if to is not None else self._cast_to\n\n        # unwrap `Annotated[T, ...]` -&gt; `T`\n        if is_annotated_type(cast_to):\n            cast_to = extract_type_arg(cast_to, 0)\n\n        if cast_to is NoneType:\n            return cast(R, None)\n\n        response = self.http_response\n        if cast_to == str:\n            return cast(R, response.text)\n\n        if cast_to == bytes:\n            return cast(R, response.content)\n\n        if cast_to == int:\n            return cast(R, int(response.text))\n\n        if cast_to == float:\n            return cast(R, float(response.text))\n\n        origin = get_origin(cast_to) or cast_to\n\n        # handle the legacy binary response case\n        if inspect.isclass(cast_to) and cast_to.__name__ == \"HttpxBinaryResponseContent\":\n            return cast(R, cast_to(response))  # type: ignore\n\n        if origin == APIResponse:\n            raise RuntimeError(\"Unexpected state - cast_to is `APIResponse`\")\n\n        if inspect.isclass(origin) and issubclass(origin, httpx.Response):\n            # Because of the invariance of our ResponseT TypeVar, users can subclass httpx.Response\n            # and pass that class to our request functions. We cannot change the variance to be either\n            # covariant or contravariant as that makes our usage of ResponseT illegal. We could construct\n            # the response class ourselves but that is something that should be supported directly in httpx\n            # as it would be easy to incorrectly construct the Response object due to the multitude of arguments.\n            if cast_to != httpx.Response:\n                raise ValueError(f\"Subclasses of httpx.Response cannot be passed to `cast_to`\")\n            return cast(R, response)\n\n        if inspect.isclass(origin) and not issubclass(origin, BaseModel) and issubclass(origin, pydantic.BaseModel):\n            raise TypeError(\"Pydantic models must subclass our base model type, e.g. `from anthropic import BaseModel`\")\n\n        if (\n            cast_to is not object\n            and not origin is list\n            and not origin is dict\n            and not origin is Union\n            and not issubclass(origin, BaseModel)\n        ):\n            raise RuntimeError(\n                f\"Unsupported type, expected {cast_to} to be a subclass of {BaseModel}, {dict}, {list}, {Union}, {NoneType}, {str} or {httpx.Response}.\"\n            )\n\n        # split is required to handle cases where additional information is included\n        # in the response, e.g. application/json; charset=utf-8\n        content_type, *_ = response.headers.get(\"content-type\", \"*\").split(\";\")\n        if content_type != \"application/json\":\n            if is_basemodel(cast_to):\n                try:\n                    data = response.json()\n                except Exception as exc:\n                    log.debug(\"Could not read JSON from response data due to %s - %s\", type(exc), exc)\n                else:\n                    return self._client._process_response_data(\n                        data=data,\n                        cast_to=cast_to,  # type: ignore\n                        response=response,\n                    )\n\n            if self._client._strict_response_validation:\n                raise APIResponseValidationError(\n                    response=response,\n                    message=f\"Expected Content-Type response header to be `application/json` but received `{content_type}` instead.\",\n                    body=response.text,\n                )\n\n            # If the API responds with content that isn't JSON then we just return\n            # the (decoded) text without performing any parsing so that you can still\n            # handle the response however you need to.\n            return response.text  # type: ignore\n\n        data = response.json()\n\n        return self._client._process_response_data(\n            data=data,\n            cast_to=cast_to,  # type: ignore\n            response=response,\n        )\n</code></pre>"},{"location":"_response/#_response.BaseAPIResponse.elapsed","title":"<code>elapsed: datetime.timedelta</code>  <code>property</code>","text":"<p>The time taken for the complete request/response cycle to complete.</p>"},{"location":"_response/#_response.BaseAPIResponse.http_request","title":"<code>http_request: httpx.Request</code>  <code>property</code>","text":"<p>Returns the httpx Request instance associated with the current response.</p>"},{"location":"_response/#_response.BaseAPIResponse.is_closed","title":"<code>is_closed: bool</code>  <code>property</code>","text":"<p>Whether or not the response body has been closed.</p> <p>If this is False then there is response data that has not been read yet. You must either fully consume the response body or call <code>.close()</code> before discarding the response to prevent resource leaks.</p>"},{"location":"_response/#_response.BaseAPIResponse.url","title":"<code>url: httpx.URL</code>  <code>property</code>","text":"<p>Returns the URL for which the request was made.</p>"},{"location":"_response/#_response.BinaryAPIResponse","title":"<code>BinaryAPIResponse</code>","text":"<p>             Bases: <code>APIResponse[bytes]</code></p> <p>Subclass of APIResponse providing helpers for dealing with binary data.</p> <p>Note: If you want to stream the response data instead of eagerly reading it all at once then you should use <code>.with_streaming_response</code> when making the API request, e.g. <code>.with_streaming_response.get_binary_response()</code></p> Source code in <code>src/anthropic/_response.py</code> <pre><code>class BinaryAPIResponse(APIResponse[bytes]):\n    \"\"\"Subclass of APIResponse providing helpers for dealing with binary data.\n\n    Note: If you want to stream the response data instead of eagerly reading it\n    all at once then you should use `.with_streaming_response` when making\n    the API request, e.g. `.with_streaming_response.get_binary_response()`\n    \"\"\"\n\n    def write_to_file(\n        self,\n        file: str | os.PathLike[str],\n    ) -&gt; None:\n        \"\"\"Write the output to the given file.\n\n        Accepts a filename or any path-like object, e.g. pathlib.Path\n\n        Note: if you want to stream the data to the file instead of writing\n        all at once then you should use `.with_streaming_response` when making\n        the API request, e.g. `.with_streaming_response.get_binary_response()`\n        \"\"\"\n        with open(file, mode=\"wb\") as f:\n            for data in self.iter_bytes():\n                f.write(data)\n</code></pre>"},{"location":"_response/#_response.BinaryAPIResponse.write_to_file","title":"<code>write_to_file(file)</code>","text":"<p>Write the output to the given file.</p> <p>Accepts a filename or any path-like object, e.g. pathlib.Path</p> <p>Note: if you want to stream the data to the file instead of writing all at once then you should use <code>.with_streaming_response</code> when making the API request, e.g. <code>.with_streaming_response.get_binary_response()</code></p> Source code in <code>src/anthropic/_response.py</code> <pre><code>def write_to_file(\n    self,\n    file: str | os.PathLike[str],\n) -&gt; None:\n    \"\"\"Write the output to the given file.\n\n    Accepts a filename or any path-like object, e.g. pathlib.Path\n\n    Note: if you want to stream the data to the file instead of writing\n    all at once then you should use `.with_streaming_response` when making\n    the API request, e.g. `.with_streaming_response.get_binary_response()`\n    \"\"\"\n    with open(file, mode=\"wb\") as f:\n        for data in self.iter_bytes():\n            f.write(data)\n</code></pre>"},{"location":"_response/#_response.ResponseContextManager","title":"<code>ResponseContextManager</code>","text":"<p>             Bases: <code>Generic[_APIResponseT]</code></p> <p>Context manager for ensuring that a request is not made until it is entered and that the response will always be closed when the context manager exits</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>class ResponseContextManager(Generic[_APIResponseT]):\n    \"\"\"Context manager for ensuring that a request is not made\n    until it is entered and that the response will always be closed\n    when the context manager exits\n    \"\"\"\n\n    def __init__(self, request_func: Callable[[], _APIResponseT]) -&gt; None:\n        self._request_func = request_func\n        self.__response: _APIResponseT | None = None\n\n    def __enter__(self) -&gt; _APIResponseT:\n        self.__response = self._request_func()\n        return self.__response\n\n    def __exit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc: BaseException | None,\n        exc_tb: TracebackType | None,\n    ) -&gt; None:\n        if self.__response is not None:\n            self.__response.close()\n</code></pre>"},{"location":"_response/#_response.StreamAlreadyConsumed","title":"<code>StreamAlreadyConsumed</code>","text":"<p>             Bases: <code>AnthropicError</code></p> <p>Attempted to read or stream content, but the content has already been streamed.</p> <p>This can happen if you use a method like <code>.iter_lines()</code> and then attempt to read th entire response body afterwards, e.g.</p> <pre><code>response = await client.post(...)\nasync for line in response.iter_lines():\n    ...  # do something with `line`\n\ncontent = await response.read()\n# ^ error\n</code></pre> <p>If you want this behaviour you'll need to either manually accumulate the response content or call <code>await response.read()</code> before iterating over the stream.</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>class StreamAlreadyConsumed(AnthropicError):\n    \"\"\"\n    Attempted to read or stream content, but the content has already\n    been streamed.\n\n    This can happen if you use a method like `.iter_lines()` and then attempt\n    to read th entire response body afterwards, e.g.\n\n    ```py\n    response = await client.post(...)\n    async for line in response.iter_lines():\n        ...  # do something with `line`\n\n    content = await response.read()\n    # ^ error\n    ```\n\n    If you want this behaviour you'll need to either manually accumulate the response\n    content or call `await response.read()` before iterating over the stream.\n    \"\"\"\n\n    def __init__(self) -&gt; None:\n        message = (\n            \"Attempted to read or stream some content, but the content has \"\n            \"already been streamed. \"\n            \"This could be due to attempting to stream the response \"\n            \"content more than once.\"\n            \"\\n\\n\"\n            \"You can fix this by manually accumulating the response content while streaming \"\n            \"or by calling `.read()` before starting to stream.\"\n        )\n        super().__init__(message)\n</code></pre>"},{"location":"_response/#_response.StreamedBinaryAPIResponse","title":"<code>StreamedBinaryAPIResponse</code>","text":"<p>             Bases: <code>APIResponse[bytes]</code></p> Source code in <code>src/anthropic/_response.py</code> <pre><code>class StreamedBinaryAPIResponse(APIResponse[bytes]):\n    def stream_to_file(\n        self,\n        file: str | os.PathLike[str],\n        *,\n        chunk_size: int | None = None,\n    ) -&gt; None:\n        \"\"\"Streams the output to the given file.\n\n        Accepts a filename or any path-like object, e.g. pathlib.Path\n        \"\"\"\n        with open(file, mode=\"wb\") as f:\n            for data in self.iter_bytes(chunk_size):\n                f.write(data)\n</code></pre>"},{"location":"_response/#_response.StreamedBinaryAPIResponse.stream_to_file","title":"<code>stream_to_file(file, *, chunk_size=None)</code>","text":"<p>Streams the output to the given file.</p> <p>Accepts a filename or any path-like object, e.g. pathlib.Path</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>def stream_to_file(\n    self,\n    file: str | os.PathLike[str],\n    *,\n    chunk_size: int | None = None,\n) -&gt; None:\n    \"\"\"Streams the output to the given file.\n\n    Accepts a filename or any path-like object, e.g. pathlib.Path\n    \"\"\"\n    with open(file, mode=\"wb\") as f:\n        for data in self.iter_bytes(chunk_size):\n            f.write(data)\n</code></pre>"},{"location":"_response/#_response.async_to_custom_raw_response_wrapper","title":"<code>async_to_custom_raw_response_wrapper(func, response_cls)</code>","text":"<p>Higher order function that takes one of our bound API methods and an <code>APIResponse</code> class and wraps the method to support returning the given response class directly.</p> <p>Note: the given <code>response_cls</code> must be concrete, e.g. <code>class BinaryAPIResponse(APIResponse[bytes])</code></p> Source code in <code>src/anthropic/_response.py</code> <pre><code>def async_to_custom_raw_response_wrapper(\n    func: Callable[P, Awaitable[object]],\n    response_cls: type[_AsyncAPIResponseT],\n) -&gt; Callable[P, Awaitable[_AsyncAPIResponseT]]:\n    \"\"\"Higher order function that takes one of our bound API methods and an `APIResponse` class\n    and wraps the method to support returning the given response class directly.\n\n    Note: the given `response_cls` *must* be concrete, e.g. `class BinaryAPIResponse(APIResponse[bytes])`\n    \"\"\"\n\n    @functools.wraps(func)\n    def wrapped(*args: P.args, **kwargs: P.kwargs) -&gt; Awaitable[_AsyncAPIResponseT]:\n        extra_headers: dict[str, Any] = {**(cast(Any, kwargs.get(\"extra_headers\")) or {})}\n        extra_headers[RAW_RESPONSE_HEADER] = \"raw\"\n        extra_headers[OVERRIDE_CAST_TO_HEADER] = response_cls\n\n        kwargs[\"extra_headers\"] = extra_headers\n\n        return cast(Awaitable[_AsyncAPIResponseT], func(*args, **kwargs))\n\n    return wrapped\n</code></pre>"},{"location":"_response/#_response.async_to_custom_streamed_response_wrapper","title":"<code>async_to_custom_streamed_response_wrapper(func, response_cls)</code>","text":"<p>Higher order function that takes one of our bound API methods and an <code>APIResponse</code> class and wraps the method to support streaming and returning the given response class directly.</p> <p>Note: the given <code>response_cls</code> must be concrete, e.g. <code>class BinaryAPIResponse(APIResponse[bytes])</code></p> Source code in <code>src/anthropic/_response.py</code> <pre><code>def async_to_custom_streamed_response_wrapper(\n    func: Callable[P, Awaitable[object]],\n    response_cls: type[_AsyncAPIResponseT],\n) -&gt; Callable[P, AsyncResponseContextManager[_AsyncAPIResponseT]]:\n    \"\"\"Higher order function that takes one of our bound API methods and an `APIResponse` class\n    and wraps the method to support streaming and returning the given response class directly.\n\n    Note: the given `response_cls` *must* be concrete, e.g. `class BinaryAPIResponse(APIResponse[bytes])`\n    \"\"\"\n\n    @functools.wraps(func)\n    def wrapped(*args: P.args, **kwargs: P.kwargs) -&gt; AsyncResponseContextManager[_AsyncAPIResponseT]:\n        extra_headers: dict[str, Any] = {**(cast(Any, kwargs.get(\"extra_headers\")) or {})}\n        extra_headers[RAW_RESPONSE_HEADER] = \"stream\"\n        extra_headers[OVERRIDE_CAST_TO_HEADER] = response_cls\n\n        kwargs[\"extra_headers\"] = extra_headers\n\n        make_request = func(*args, **kwargs)\n\n        return AsyncResponseContextManager(cast(Awaitable[_AsyncAPIResponseT], make_request))\n\n    return wrapped\n</code></pre>"},{"location":"_response/#_response.async_to_raw_response_wrapper","title":"<code>async_to_raw_response_wrapper(func)</code>","text":"<p>Higher order function that takes one of our bound API methods and wraps it to support returning the raw <code>APIResponse</code> object directly.</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>def async_to_raw_response_wrapper(func: Callable[P, Awaitable[R]]) -&gt; Callable[P, Awaitable[AsyncAPIResponse[R]]]:\n    \"\"\"Higher order function that takes one of our bound API methods and wraps it\n    to support returning the raw `APIResponse` object directly.\n    \"\"\"\n\n    @functools.wraps(func)\n    async def wrapped(*args: P.args, **kwargs: P.kwargs) -&gt; AsyncAPIResponse[R]:\n        extra_headers: dict[str, str] = {**(cast(Any, kwargs.get(\"extra_headers\")) or {})}\n        extra_headers[RAW_RESPONSE_HEADER] = \"raw\"\n\n        kwargs[\"extra_headers\"] = extra_headers\n\n        return cast(AsyncAPIResponse[R], await func(*args, **kwargs))\n\n    return wrapped\n</code></pre>"},{"location":"_response/#_response.async_to_streamed_response_wrapper","title":"<code>async_to_streamed_response_wrapper(func)</code>","text":"<p>Higher order function that takes one of our bound API methods and wraps it to support streaming and returning the raw <code>APIResponse</code> object directly.</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>def async_to_streamed_response_wrapper(\n    func: Callable[P, Awaitable[R]],\n) -&gt; Callable[P, AsyncResponseContextManager[AsyncAPIResponse[R]]]:\n    \"\"\"Higher order function that takes one of our bound API methods and wraps it\n    to support streaming and returning the raw `APIResponse` object directly.\n    \"\"\"\n\n    @functools.wraps(func)\n    def wrapped(*args: P.args, **kwargs: P.kwargs) -&gt; AsyncResponseContextManager[AsyncAPIResponse[R]]:\n        extra_headers: dict[str, str] = {**(cast(Any, kwargs.get(\"extra_headers\")) or {})}\n        extra_headers[RAW_RESPONSE_HEADER] = \"stream\"\n\n        kwargs[\"extra_headers\"] = extra_headers\n\n        make_request = func(*args, **kwargs)\n\n        return AsyncResponseContextManager(cast(Awaitable[AsyncAPIResponse[R]], make_request))\n\n    return wrapped\n</code></pre>"},{"location":"_response/#_response.extract_response_type","title":"<code>extract_response_type(typ)</code>","text":"<p>Given a type like <code>APIResponse[T]</code>, returns the generic type variable <code>T</code>.</p> <p>This also handles the case where a concrete subclass is given, e.g.</p> <pre><code>class MyResponse(APIResponse[bytes]):\n    ...\n\nextract_response_type(MyResponse) -&gt; bytes\n</code></pre> Source code in <code>src/anthropic/_response.py</code> <pre><code>def extract_response_type(typ: type[BaseAPIResponse[Any]]) -&gt; type:\n    \"\"\"Given a type like `APIResponse[T]`, returns the generic type variable `T`.\n\n    This also handles the case where a concrete subclass is given, e.g.\n    ```py\n    class MyResponse(APIResponse[bytes]):\n        ...\n\n    extract_response_type(MyResponse) -&gt; bytes\n    ```\n    \"\"\"\n    return extract_type_var_from_base(\n        typ,\n        generic_bases=cast(\"tuple[type, ...]\", (BaseAPIResponse, APIResponse, AsyncAPIResponse)),\n        index=0,\n    )\n</code></pre>"},{"location":"_response/#_response.to_custom_raw_response_wrapper","title":"<code>to_custom_raw_response_wrapper(func, response_cls)</code>","text":"<p>Higher order function that takes one of our bound API methods and an <code>APIResponse</code> class and wraps the method to support returning the given response class directly.</p> <p>Note: the given <code>response_cls</code> must be concrete, e.g. <code>class BinaryAPIResponse(APIResponse[bytes])</code></p> Source code in <code>src/anthropic/_response.py</code> <pre><code>def to_custom_raw_response_wrapper(\n    func: Callable[P, object],\n    response_cls: type[_APIResponseT],\n) -&gt; Callable[P, _APIResponseT]:\n    \"\"\"Higher order function that takes one of our bound API methods and an `APIResponse` class\n    and wraps the method to support returning the given response class directly.\n\n    Note: the given `response_cls` *must* be concrete, e.g. `class BinaryAPIResponse(APIResponse[bytes])`\n    \"\"\"\n\n    @functools.wraps(func)\n    def wrapped(*args: P.args, **kwargs: P.kwargs) -&gt; _APIResponseT:\n        extra_headers: dict[str, Any] = {**(cast(Any, kwargs.get(\"extra_headers\")) or {})}\n        extra_headers[RAW_RESPONSE_HEADER] = \"raw\"\n        extra_headers[OVERRIDE_CAST_TO_HEADER] = response_cls\n\n        kwargs[\"extra_headers\"] = extra_headers\n\n        return cast(_APIResponseT, func(*args, **kwargs))\n\n    return wrapped\n</code></pre>"},{"location":"_response/#_response.to_custom_streamed_response_wrapper","title":"<code>to_custom_streamed_response_wrapper(func, response_cls)</code>","text":"<p>Higher order function that takes one of our bound API methods and an <code>APIResponse</code> class and wraps the method to support streaming and returning the given response class directly.</p> <p>Note: the given <code>response_cls</code> must be concrete, e.g. <code>class BinaryAPIResponse(APIResponse[bytes])</code></p> Source code in <code>src/anthropic/_response.py</code> <pre><code>def to_custom_streamed_response_wrapper(\n    func: Callable[P, object],\n    response_cls: type[_APIResponseT],\n) -&gt; Callable[P, ResponseContextManager[_APIResponseT]]:\n    \"\"\"Higher order function that takes one of our bound API methods and an `APIResponse` class\n    and wraps the method to support streaming and returning the given response class directly.\n\n    Note: the given `response_cls` *must* be concrete, e.g. `class BinaryAPIResponse(APIResponse[bytes])`\n    \"\"\"\n\n    @functools.wraps(func)\n    def wrapped(*args: P.args, **kwargs: P.kwargs) -&gt; ResponseContextManager[_APIResponseT]:\n        extra_headers: dict[str, Any] = {**(cast(Any, kwargs.get(\"extra_headers\")) or {})}\n        extra_headers[RAW_RESPONSE_HEADER] = \"stream\"\n        extra_headers[OVERRIDE_CAST_TO_HEADER] = response_cls\n\n        kwargs[\"extra_headers\"] = extra_headers\n\n        make_request = functools.partial(func, *args, **kwargs)\n\n        return ResponseContextManager(cast(Callable[[], _APIResponseT], make_request))\n\n    return wrapped\n</code></pre>"},{"location":"_response/#_response.to_raw_response_wrapper","title":"<code>to_raw_response_wrapper(func)</code>","text":"<p>Higher order function that takes one of our bound API methods and wraps it to support returning the raw <code>APIResponse</code> object directly.</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>def to_raw_response_wrapper(func: Callable[P, R]) -&gt; Callable[P, APIResponse[R]]:\n    \"\"\"Higher order function that takes one of our bound API methods and wraps it\n    to support returning the raw `APIResponse` object directly.\n    \"\"\"\n\n    @functools.wraps(func)\n    def wrapped(*args: P.args, **kwargs: P.kwargs) -&gt; APIResponse[R]:\n        extra_headers: dict[str, str] = {**(cast(Any, kwargs.get(\"extra_headers\")) or {})}\n        extra_headers[RAW_RESPONSE_HEADER] = \"raw\"\n\n        kwargs[\"extra_headers\"] = extra_headers\n\n        return cast(APIResponse[R], func(*args, **kwargs))\n\n    return wrapped\n</code></pre>"},{"location":"_response/#_response.to_streamed_response_wrapper","title":"<code>to_streamed_response_wrapper(func)</code>","text":"<p>Higher order function that takes one of our bound API methods and wraps it to support streaming and returning the raw <code>APIResponse</code> object directly.</p> Source code in <code>src/anthropic/_response.py</code> <pre><code>def to_streamed_response_wrapper(func: Callable[P, R]) -&gt; Callable[P, ResponseContextManager[APIResponse[R]]]:\n    \"\"\"Higher order function that takes one of our bound API methods and wraps it\n    to support streaming and returning the raw `APIResponse` object directly.\n    \"\"\"\n\n    @functools.wraps(func)\n    def wrapped(*args: P.args, **kwargs: P.kwargs) -&gt; ResponseContextManager[APIResponse[R]]:\n        extra_headers: dict[str, str] = {**(cast(Any, kwargs.get(\"extra_headers\")) or {})}\n        extra_headers[RAW_RESPONSE_HEADER] = \"stream\"\n\n        kwargs[\"extra_headers\"] = extra_headers\n\n        make_request = functools.partial(func, *args, **kwargs)\n\n        return ResponseContextManager(cast(Callable[[], APIResponse[R]], make_request))\n\n    return wrapped\n</code></pre>"},{"location":"_streaming/","title":"_streaming","text":""},{"location":"_streaming/#_streaming","title":"<code>_streaming</code>","text":""},{"location":"_streaming/#_streaming.AsyncStream","title":"<code>AsyncStream</code>","text":"<p>             Bases: <code>Generic[_T]</code></p> <p>Provides the core interface to iterate over an asynchronous stream response.</p> Source code in <code>src/anthropic/_streaming.py</code> <pre><code>class AsyncStream(Generic[_T]):\n    \"\"\"Provides the core interface to iterate over an asynchronous stream response.\"\"\"\n\n    response: httpx.Response\n\n    _decoder: SSEDecoder | SSEBytesDecoder\n\n    def __init__(\n        self,\n        *,\n        cast_to: type[_T],\n        response: httpx.Response,\n        client: AsyncAnthropic,\n    ) -&gt; None:\n        self.response = response\n        self._cast_to = cast_to\n        self._client = client\n        self._decoder = client._make_sse_decoder()\n        self._iterator = self.__stream__()\n\n    async def __anext__(self) -&gt; _T:\n        return await self._iterator.__anext__()\n\n    async def __aiter__(self) -&gt; AsyncIterator[_T]:\n        async for item in self._iterator:\n            yield item\n\n    async def _iter_events(self) -&gt; AsyncIterator[ServerSentEvent]:\n        async for sse in self._decoder.aiter_bytes(self.response.aiter_bytes()):\n            yield sse\n\n    async def __stream__(self) -&gt; AsyncIterator[_T]:\n        cast_to = cast(Any, self._cast_to)\n        response = self.response\n        process_data = self._client._process_response_data\n        iterator = self._iter_events()\n\n        async for sse in iterator:\n            if sse.event == \"completion\":\n                yield process_data(data=sse.json(), cast_to=cast_to, response=response)\n\n            if (\n                sse.event == \"message_start\"\n                or sse.event == \"message_delta\"\n                or sse.event == \"message_stop\"\n                or sse.event == \"content_block_start\"\n                or sse.event == \"content_block_delta\"\n                or sse.event == \"content_block_stop\"\n            ):\n                data = sse.json()\n                if is_dict(data) and \"type\" not in data:\n                    data[\"type\"] = sse.event\n\n                yield process_data(data=data, cast_to=cast_to, response=response)\n\n            if sse.event == \"ping\":\n                continue\n\n            if sse.event == \"error\":\n                body = sse.data\n\n                try:\n                    body = sse.json()\n                    err_msg = f\"{body}\"\n                except Exception:\n                    err_msg = sse.data or f\"Error code: {response.status_code}\"\n\n                raise self._client._make_status_error(\n                    err_msg,\n                    body=body,\n                    response=self.response,\n                )\n\n        # Ensure the entire stream is consumed\n        async for _sse in iterator:\n            ...\n\n    async def __aenter__(self) -&gt; Self:\n        return self\n\n    async def __aexit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc: BaseException | None,\n        exc_tb: TracebackType | None,\n    ) -&gt; None:\n        await self.close()\n\n    async def close(self) -&gt; None:\n        \"\"\"\n        Close the response and release the connection.\n\n        Automatically called if the response body is read to completion.\n        \"\"\"\n        await self.response.aclose()\n</code></pre>"},{"location":"_streaming/#_streaming.AsyncStream.close","title":"<code>close()</code>  <code>async</code>","text":"<p>Close the response and release the connection.</p> <p>Automatically called if the response body is read to completion.</p> Source code in <code>src/anthropic/_streaming.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"\n    Close the response and release the connection.\n\n    Automatically called if the response body is read to completion.\n    \"\"\"\n    await self.response.aclose()\n</code></pre>"},{"location":"_streaming/#_streaming.SSEBytesDecoder","title":"<code>SSEBytesDecoder</code>","text":"<p>             Bases: <code>Protocol</code></p> Source code in <code>src/anthropic/_streaming.py</code> <pre><code>@runtime_checkable\nclass SSEBytesDecoder(Protocol):\n    def iter_bytes(self, iterator: Iterator[bytes]) -&gt; Iterator[ServerSentEvent]:\n        \"\"\"Given an iterator that yields raw binary data, iterate over it &amp; yield every event encountered\"\"\"\n        ...\n\n    def aiter_bytes(self, iterator: AsyncIterator[bytes]) -&gt; AsyncIterator[ServerSentEvent]:\n        \"\"\"Given an async iterator that yields raw binary data, iterate over it &amp; yield every event encountered\"\"\"\n        ...\n</code></pre>"},{"location":"_streaming/#_streaming.SSEBytesDecoder.aiter_bytes","title":"<code>aiter_bytes(iterator)</code>","text":"<p>Given an async iterator that yields raw binary data, iterate over it &amp; yield every event encountered</p> Source code in <code>src/anthropic/_streaming.py</code> <pre><code>def aiter_bytes(self, iterator: AsyncIterator[bytes]) -&gt; AsyncIterator[ServerSentEvent]:\n    \"\"\"Given an async iterator that yields raw binary data, iterate over it &amp; yield every event encountered\"\"\"\n    ...\n</code></pre>"},{"location":"_streaming/#_streaming.SSEBytesDecoder.iter_bytes","title":"<code>iter_bytes(iterator)</code>","text":"<p>Given an iterator that yields raw binary data, iterate over it &amp; yield every event encountered</p> Source code in <code>src/anthropic/_streaming.py</code> <pre><code>def iter_bytes(self, iterator: Iterator[bytes]) -&gt; Iterator[ServerSentEvent]:\n    \"\"\"Given an iterator that yields raw binary data, iterate over it &amp; yield every event encountered\"\"\"\n    ...\n</code></pre>"},{"location":"_streaming/#_streaming.SSEDecoder","title":"<code>SSEDecoder</code>","text":"Source code in <code>src/anthropic/_streaming.py</code> <pre><code>class SSEDecoder:\n    _data: list[str]\n    _event: str | None\n    _retry: int | None\n    _last_event_id: str | None\n\n    def __init__(self) -&gt; None:\n        self._event = None\n        self._data = []\n        self._last_event_id = None\n        self._retry = None\n\n    def iter_bytes(self, iterator: Iterator[bytes]) -&gt; Iterator[ServerSentEvent]:\n        \"\"\"Given an iterator that yields raw binary data, iterate over it &amp; yield every event encountered\"\"\"\n        for chunk in self._iter_chunks(iterator):\n            # Split before decoding so splitlines() only uses \\r and \\n\n            for raw_line in chunk.splitlines():\n                line = raw_line.decode(\"utf-8\")\n                sse = self.decode(line)\n                if sse:\n                    yield sse\n\n    def _iter_chunks(self, iterator: Iterator[bytes]) -&gt; Iterator[bytes]:\n        \"\"\"Given an iterator that yields raw binary data, iterate over it and yield individual SSE chunks\"\"\"\n        data = b\"\"\n        for chunk in iterator:\n            for line in chunk.splitlines(keepends=True):\n                data += line\n                if data.endswith((b\"\\r\\r\", b\"\\n\\n\", b\"\\r\\n\\r\\n\")):\n                    yield data\n                    data = b\"\"\n        if data:\n            yield data\n\n    async def aiter_bytes(self, iterator: AsyncIterator[bytes]) -&gt; AsyncIterator[ServerSentEvent]:\n        \"\"\"Given an iterator that yields raw binary data, iterate over it &amp; yield every event encountered\"\"\"\n        async for chunk in self._aiter_chunks(iterator):\n            # Split before decoding so splitlines() only uses \\r and \\n\n            for raw_line in chunk.splitlines():\n                line = raw_line.decode(\"utf-8\")\n                sse = self.decode(line)\n                if sse:\n                    yield sse\n\n    async def _aiter_chunks(self, iterator: AsyncIterator[bytes]) -&gt; AsyncIterator[bytes]:\n        \"\"\"Given an iterator that yields raw binary data, iterate over it and yield individual SSE chunks\"\"\"\n        data = b\"\"\n        async for chunk in iterator:\n            for line in chunk.splitlines(keepends=True):\n                data += line\n                if data.endswith((b\"\\r\\r\", b\"\\n\\n\", b\"\\r\\n\\r\\n\")):\n                    yield data\n                    data = b\"\"\n        if data:\n            yield data\n\n    def decode(self, line: str) -&gt; ServerSentEvent | None:\n        # See: https://html.spec.whatwg.org/multipage/server-sent-events.html#event-stream-interpretation  # noqa: E501\n\n        if not line:\n            if not self._event and not self._data and not self._last_event_id and self._retry is None:\n                return None\n\n            sse = ServerSentEvent(\n                event=self._event,\n                data=\"\\n\".join(self._data),\n                id=self._last_event_id,\n                retry=self._retry,\n            )\n\n            # NOTE: as per the SSE spec, do not reset last_event_id.\n            self._event = None\n            self._data = []\n            self._retry = None\n\n            return sse\n\n        if line.startswith(\":\"):\n            return None\n\n        fieldname, _, value = line.partition(\":\")\n\n        if value.startswith(\" \"):\n            value = value[1:]\n\n        if fieldname == \"event\":\n            self._event = value\n        elif fieldname == \"data\":\n            self._data.append(value)\n        elif fieldname == \"id\":\n            if \"\\0\" in value:\n                pass\n            else:\n                self._last_event_id = value\n        elif fieldname == \"retry\":\n            try:\n                self._retry = int(value)\n            except (TypeError, ValueError):\n                pass\n        else:\n            pass  # Field is ignored.\n\n        return None\n</code></pre>"},{"location":"_streaming/#_streaming.SSEDecoder.aiter_bytes","title":"<code>aiter_bytes(iterator)</code>  <code>async</code>","text":"<p>Given an iterator that yields raw binary data, iterate over it &amp; yield every event encountered</p> Source code in <code>src/anthropic/_streaming.py</code> <pre><code>async def aiter_bytes(self, iterator: AsyncIterator[bytes]) -&gt; AsyncIterator[ServerSentEvent]:\n    \"\"\"Given an iterator that yields raw binary data, iterate over it &amp; yield every event encountered\"\"\"\n    async for chunk in self._aiter_chunks(iterator):\n        # Split before decoding so splitlines() only uses \\r and \\n\n        for raw_line in chunk.splitlines():\n            line = raw_line.decode(\"utf-8\")\n            sse = self.decode(line)\n            if sse:\n                yield sse\n</code></pre>"},{"location":"_streaming/#_streaming.SSEDecoder.iter_bytes","title":"<code>iter_bytes(iterator)</code>","text":"<p>Given an iterator that yields raw binary data, iterate over it &amp; yield every event encountered</p> Source code in <code>src/anthropic/_streaming.py</code> <pre><code>def iter_bytes(self, iterator: Iterator[bytes]) -&gt; Iterator[ServerSentEvent]:\n    \"\"\"Given an iterator that yields raw binary data, iterate over it &amp; yield every event encountered\"\"\"\n    for chunk in self._iter_chunks(iterator):\n        # Split before decoding so splitlines() only uses \\r and \\n\n        for raw_line in chunk.splitlines():\n            line = raw_line.decode(\"utf-8\")\n            sse = self.decode(line)\n            if sse:\n                yield sse\n</code></pre>"},{"location":"_streaming/#_streaming.Stream","title":"<code>Stream</code>","text":"<p>             Bases: <code>Generic[_T]</code></p> <p>Provides the core interface to iterate over a synchronous stream response.</p> Source code in <code>src/anthropic/_streaming.py</code> <pre><code>class Stream(Generic[_T]):\n    \"\"\"Provides the core interface to iterate over a synchronous stream response.\"\"\"\n\n    response: httpx.Response\n\n    _decoder: SSEBytesDecoder\n\n    def __init__(\n        self,\n        *,\n        cast_to: type[_T],\n        response: httpx.Response,\n        client: Anthropic,\n    ) -&gt; None:\n        self.response = response\n        self._cast_to = cast_to\n        self._client = client\n        self._decoder = client._make_sse_decoder()\n        self._iterator = self.__stream__()\n\n    def __next__(self) -&gt; _T:\n        return self._iterator.__next__()\n\n    def __iter__(self) -&gt; Iterator[_T]:\n        for item in self._iterator:\n            yield item\n\n    def _iter_events(self) -&gt; Iterator[ServerSentEvent]:\n        yield from self._decoder.iter_bytes(self.response.iter_bytes())\n\n    def __stream__(self) -&gt; Iterator[_T]:\n        cast_to = cast(Any, self._cast_to)\n        response = self.response\n        process_data = self._client._process_response_data\n        iterator = self._iter_events()\n\n        for sse in iterator:\n            if sse.event == \"completion\":\n                yield process_data(data=sse.json(), cast_to=cast_to, response=response)\n\n            if (\n                sse.event == \"message_start\"\n                or sse.event == \"message_delta\"\n                or sse.event == \"message_stop\"\n                or sse.event == \"content_block_start\"\n                or sse.event == \"content_block_delta\"\n                or sse.event == \"content_block_stop\"\n            ):\n                data = sse.json()\n                if is_dict(data) and \"type\" not in data:\n                    data[\"type\"] = sse.event\n\n                yield process_data(data=data, cast_to=cast_to, response=response)\n\n            if sse.event == \"ping\":\n                continue\n\n            if sse.event == \"error\":\n                body = sse.data\n\n                try:\n                    body = sse.json()\n                    err_msg = f\"{body}\"\n                except Exception:\n                    err_msg = sse.data or f\"Error code: {response.status_code}\"\n\n                raise self._client._make_status_error(\n                    err_msg,\n                    body=body,\n                    response=self.response,\n                )\n\n        # Ensure the entire stream is consumed\n        for _sse in iterator:\n            ...\n\n    def __enter__(self) -&gt; Self:\n        return self\n\n    def __exit__(\n        self,\n        exc_type: type[BaseException] | None,\n        exc: BaseException | None,\n        exc_tb: TracebackType | None,\n    ) -&gt; None:\n        self.close()\n\n    def close(self) -&gt; None:\n        \"\"\"\n        Close the response and release the connection.\n\n        Automatically called if the response body is read to completion.\n        \"\"\"\n        self.response.close()\n</code></pre>"},{"location":"_streaming/#_streaming.Stream.close","title":"<code>close()</code>","text":"<p>Close the response and release the connection.</p> <p>Automatically called if the response body is read to completion.</p> Source code in <code>src/anthropic/_streaming.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"\n    Close the response and release the connection.\n\n    Automatically called if the response body is read to completion.\n    \"\"\"\n    self.response.close()\n</code></pre>"},{"location":"_streaming/#_streaming.extract_stream_chunk_type","title":"<code>extract_stream_chunk_type(stream_cls, *, failure_message=None)</code>","text":"<p>Given a type like <code>Stream[T]</code>, returns the generic type variable <code>T</code>.</p> <p>This also handles the case where a concrete subclass is given, e.g.</p> <pre><code>class MyStream(Stream[bytes]):\n    ...\n\nextract_stream_chunk_type(MyStream) -&gt; bytes\n</code></pre> Source code in <code>src/anthropic/_streaming.py</code> <pre><code>def extract_stream_chunk_type(\n    stream_cls: type,\n    *,\n    failure_message: str | None = None,\n) -&gt; type:\n    \"\"\"Given a type like `Stream[T]`, returns the generic type variable `T`.\n\n    This also handles the case where a concrete subclass is given, e.g.\n    ```py\n    class MyStream(Stream[bytes]):\n        ...\n\n    extract_stream_chunk_type(MyStream) -&gt; bytes\n    ```\n    \"\"\"\n    from ._base_client import Stream, AsyncStream\n\n    return extract_type_var_from_base(\n        stream_cls,\n        index=0,\n        generic_bases=cast(\"tuple[type, ...]\", (Stream, AsyncStream)),\n        failure_message=failure_message,\n    )\n</code></pre>"},{"location":"_streaming/#_streaming.is_stream_class_type","title":"<code>is_stream_class_type(typ)</code>","text":"<p>TypeGuard for determining whether or not the given type is a subclass of <code>Stream</code> / <code>AsyncStream</code></p> Source code in <code>src/anthropic/_streaming.py</code> <pre><code>def is_stream_class_type(typ: type) -&gt; TypeGuard[type[Stream[object]] | type[AsyncStream[object]]]:\n    \"\"\"TypeGuard for determining whether or not the given type is a subclass of `Stream` / `AsyncStream`\"\"\"\n    origin = get_origin(typ) or typ\n    return inspect.isclass(origin) and issubclass(origin, (Stream, AsyncStream))\n</code></pre>"}]}